# -*- coding: utf-8 -*-
"""langchain_tutorial-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1544V7c2IgEXw8RkG97fcXdWaulUPbKcn
"""

from dotenv import load_dotenv

load_dotenv()

# os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_groq import ChatGroq
from langchain_openai import ChatOpenAI
#from langchain_anthropic import ChatAnthropic
from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint

llm=HuggingFaceEndpoint(repo_id="TinyLlama/TinyLlama-1.1B-Chat-v1.0",task="text-generation")

model=ChatHuggingFace(llm=llm)

model.invoke("what is capital of USA?").content

gemini_model=ChatGoogleGenerativeAI(model='gemini-1.5-pro')

gemini_model.invoke("what is capital of USA?")

groq_model=ChatGroq(model="deepseek-r1-distill-llama-70b")

groq_model.invoke("what is capital of USA")

openai_model=ChatOpenAI(model="gpt-4")

openai_model.invoke("what is capital of USA")

from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline

llm = HuggingFacePipeline.from_model_id(
    model_id='TinyLlama/TinyLlama-1.1B-Chat-v1.0',
    task='text-generation',
    pipeline_kwargs=dict(
        temperature=0.5,
        max_new_tokens=100
    )
)

model = ChatHuggingFace(llm=llm)

"""# Embedding Models"""

from langchain_openai import OpenAIEmbeddings

openai_embedding=OpenAIEmbeddings(model='text-embedding-3-large')

result=openai_embedding.embed_query("India is a growing country")

len(result)

openai_embedding_small=OpenAIEmbeddings(model='text-embedding-3-small')

result2=openai_embedding_small.embed_query("India is a growing country")

len(result2)

openai_embedding_64=OpenAIEmbeddings(model='text-embedding-3-large',dimensions=64)

result3=openai_embedding_64.embed_query("India is a growing country")

len(result3)

documents=["what is a capital of USA",
           "who is a president of usa",
           "who is a prime minister of india"]

result=openai_embedding.embed_documents(documents)

len(result)

result[0]

documents=["what is a capital of USA",
           "who is a president of usa",
           "who is a prime minister of india"]

my_query="narendra modi is indian prime minister"

query_embedding=openai_embedding.embed_query(my_query)
document_embedding=openai_embedding.embed_documents(documents)

document_embedding

from sklearn.metrics.pairwise import cosine_similarity

scores=cosine_similarity([query_embedding],document_embedding)

scores

from langchain_huggingface import HuggingFaceEmbeddings
huggingface_embeddings=HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

from langchain_google_genai import GoogleGenerativeAIEmbeddings
google_embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

"""# PROMPTS or PROMPT_TEMPLATE"""

from langchain_core.messages import SystemMessage,HumanMessage,AIMessage

My_Model:"GPT"
System_Message: "You are healthcare chatbot."
Human_Message or User_Message: "can you suggest me a best medicine for fever?"
AI_Message or Model_Generated_Message: "paracetamol/DOLO650 is a best medicine for fever."

SystemMessage(content="you are a funny bot means whatever you answer, you answer in the funny way")

HumanMessage(content="who is your best friend")

messages=[SystemMessage(content="you are a funny bot means whatever you answer, you answer in the funny way"),
          HumanMessage(content="who is your best friend")]

messages2=[SystemMessage(content="you are angery young man, you answer everything in rude way"),
          HumanMessage(content="who is your best friend")]

openai_model.invoke(messages).content

openai_model.invoke(messages2).content

messages3=[SystemMessage(content="you are very helpful assistance you answer everything in detail"),
          HumanMessage(content="tell me the role of langchain in AI devlopment")]

messages3.append(AIMessage(openai_model.invoke(messages3).content))

messages3

"""# Create a chabtbot"""

chat_history = [
    SystemMessage(content="you are a helpful assistant")
]

while True:
    user_input=input("user_input: ")
    chat_history.append(HumanMessage(content=user_input))
    if user_input=="exit":
        break
    result=openai_model.invoke(chat_history)
    chat_history.append(AIMessage(result.content))
    print("AI Generated Answer:", result.content)

print(chat_history)

from langchain_core.prompts import PromptTemplate

template=PromptTemplate(
    template="can you say hello to {name} in 5 different language",
    input_variables=['name']
)

template

template.get_prompts()

template.invoke({"name":"sunny"})

template.invoke({"name":"krish"})

prompt=template.invoke({"name":"virat kholi"})

openai_model.invoke(prompt).content

# template=PromptTemplate(
#     template="can you say hello to {name} in 5 different language",
#     input_variables=['name']
# )

# openai_model.invoke({'name':'sunny'}).content

"""rest of the prompting
output parser
chaining
text splitting
vector database
"""

# openai_model.invoke({"name":"sunny"})

System_Message
HumanMessage
AIMessage

from langchain_core.prompts import ChatPromptTemplate

chat_template=ChatPromptTemplate(
    [
        ("system","you are a helpful {domain} expert"),
        ("human","explain the {topic} in simple terms")
    ]
)

prompt = chat_template.invoke({"domain":"medical","topic":"maleria"})

print(prompt)

messages=[SystemMessage(content='you are a helpful medical expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='explain the maleria in simple terms', additional_kwargs={}, response_metadata={})]

openai_model.invoke(prompt).content

prompt = chat_template.invoke({"domain":"education","topic":"AI"})

print(prompt)

openai_model.invoke(prompt)

"""# Chaining using LCEL"""

from langchain_core.output_parsers import StrOutputParser

parser=StrOutputParser()

parser

prompt=PromptTemplate(
    template="can you give me a detail explaination of {topic}",
    input_variables=['topic']

)

prompt

openai_model

"""### Simple llm chain"""

chain=prompt | openai_model | parser

chain.invoke({"topic":"machine learning"})

chain.get_graph().print_ascii()

"""## Sequential llm chain"""

prompt1=PromptTemplate(
    template="get a detail report on {topic}",
    input_variables=["topic"]
)

prompt2=PromptTemplate(
    template="generate a 3 point of summary from the following {text}",
    input_variables=["text"]
)

text="""In November 2023, xAI began previewing Grok as a chatbot to selected people,[10] with participation in the early access program being limited to paid X Premium users.[11]

It was announced that once the bot was out of early beta, it would only be available to higher tier X Premium+ subscribers.[12]

At the time of the preview, xAI described the chatbot as "a very early beta product – the best we could do with 2 months of training" that could "improve rapidly with each passing week".[13]

On March 11, 2024, Musk posted on X that the language model would go open source within a week. Six days later, on March 17, Grok-1 was open sourced under the Apache-2.0 license.[14][15] Disclosed were the networks architecture and its weight parameters.[16]

On March 26, 2024, Musk announced that Grok would be enabled for premium subscribers, not just those on the higher-end tier, Premium+.[17]

Grok-1.5
Grok-1.5
Developer(s)	xAI
Initial release	May 15, 2024; 10 months ago
Predecessor	Grok-1.5
Successor	Grok-2
Type
Large language model
Foundation model
License	Proprietary
Website	x.ai/blog/grok-1.5
On March 29, 2024, Grok-1.5 was announced, with "improved reasoning capabilities" and a context length of 128,000 tokens.[18] Grok-1.5 was released to all X Premium users on May 15, 2024.[1]

On April 4, 2024, an update to X's "Explore" page included summaries of breaking news stories written by Grok, a task previously assigned to a human curation team.[19]

On April 12, 2024, Grok-1.5 Vision (Grok-1.5V) was announced. Grok-1.5V is able to process a wide variety of visual information, including documents, diagrams, graphs, screenshots, and photographs.[20] Grok-1.5V was never released to the public.

On May 4, 2024, Grok became available in the United Kingdom,[21] that being the only country in Europe to support Grok at the moment due to the impending Artificial Intelligence Act rules in the European Union. Grok was later reviewed by the EU and was released on May 16, 2024.[22]"""

prompt1=PromptTemplate(
    template="analysis the the given text carefully {text} and take the necessary data",
    input_variables=["topic"]
)

prompt2=PromptTemplate(
    template="summarize the given text in 2 bullet points {text}",
    input_variables=["text"]
)

openai_model

parser

chain = prompt1 | openai_model | parser | prompt2 | openai_model | parser

chain.get_graph().print_ascii()

result=chain.invoke({"text":text})

print(result)

"""## Parallel Chain"""

prompt1=PromptTemplate(
    template="generate simple summary from the following text \n {text}",
    input_variables=["text"]
)

prompt2=PromptTemplate(
    template="generate 3 question and answer from the following text \n {text}",
    input_variables=["text"]
    )

prompt3=PromptTemplate(
    template="analysis the summary and qa and generate the 5 important quiz with 4 possible answer \n summary: {summary}, Q&A: {qa}",
    input_variables=["summary","qa"]
)

from langchain.schema.runnable import RunnableParallel

parallel_chain=RunnableParallel({
    "summary": prompt1 | openai_model | parser,
    "qa" : prompt2 | openai_model | parser
}
)

parallel_chain

parallel_chain.invoke({"text":text})

{'summary': 'Intelligent agents are a form of digital agency that actively pursues its goals, makes decisions, and takes actions over time. They vary in complexity, from basic control systems to complex human-like entities. These agents operate based on an objective function that represents their goals and plans actions to maximize its expected value. They are a topic of study in various fields, including artificial intelligence, economics, cognitive science, ethics, and philosophy. They can be described as abstract functional systems and are often closely related to software agents that perform tasks for users.\n\nIn other terms, intelligent agents are computer programs designed to independently achieve specific objectives, embodying a new level of digital agency by making proactive, goal-oriented decisions over time. They range from simple control mechanisms like thermostats to advanced, human-like systems. These agents are informed by an objective function representing their goals and work towards maximizing its value. They are not only pivotal in AI but also hold importance in fields like economics, cognitive science, philosophy, and ethics.',
 'qa': '1) What is an example of a simple intelligent agent?\nAnswer: A basic thermostat or control system is considered a simple intelligent agent.\n\n2) What encapsulates the goals of an intelligent agent and forms the basis for its operations?\nAnswer: An objective function encapsulates the goals of an intelligent agent and forms the basis for its operations. \n\n3) What are software agents in the field of artificial intelligence and how are they related to intelligent agents?\nAnswer: Software agents are autonomous computer programs that carry out tasks on behalf of users. They are closely related to intelligent agents, often performing tasks and decision making in a proactive manner.'}

Intelligent agents, also known as AI agents, are preemptive agents that perform certain actions to achieve predefined goals. They extend the concept of conventional agents by not only responding but also acting preemptively, making decisions, and taking actions over an extended period. These AI agents can range from simple systems like a thermostat to more complex beings like humans or even larger systems such as firms, states, or biomes.

The behavior of these intelligent agents is driven by an objective function that encapsulates their targets. They function with the aim of maximizing the expected value of this objective function. Notable examples include a reinforcement learning agent guided by a reward function, and an evolutionary algorithm steered by a fitness function. The reward function for the reinforcement learning agent plays a crucial role by allowing programmers to shape its desired behavior. Similarly, the fitness function acts as the steering wheel for an evolutionary algorithm's behavior.

The paradigms of intelligent agents are probed in various fields such as cognitive science, ethics, philosophy, and computer social simulations. These agents are often described in abstract terms, making them highly similar to computer programs. This schematic description often results in them being referred to as abstract intelligent agents or, borrowing a term from economics, "rational agents". Also, they have a close relation to software agents, which are autonomous computer programs that carry out tasks on behalf of users. Such software agents are another key application of the concept of intelligent agents

merge_chain= prompt3 | openai_model | parser

chain = parallel_chain | merge_chain

chain.get_graph().print_ascii()

text="""AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods, thereby exemplifying a novel form of digital agency.[1]

Intelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria—such as a firm, a state, or a biome.[2]

Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion.[3] For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior.[4] Similarly, an evolutionary algorithm's behavior is guided by a fitness function.[5]

Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.

Intelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents—autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a "rational agent".[2]"""

result=chain.invoke({"text":text})

print(result)

"""## Lets understand the parser now"""

template=PromptTemplate(
    template="generate a prices 3 point summary from given text /n {text}",
    input_variables=["text"]
)

chain = template | openai_model

chain_parser = template | openai_model | parser

chain.invoke({"text":text})

chain_parser.invoke({"text":text})

"""#### json output parser"""

from langchain_core.output_parsers import JsonOutputParser

parser=JsonOutputParser()

parser.get_format_instructions()

template=PromptTemplate(
    template="give me name, age and city from the provided text {text} \n {format_instructions}" ,
    input_variables=['text'],
    partial_variables={"format_instructions":parser.get_format_instructions()}
)

text="""hi my name is sunny savita my age is 29 and i am belong to bengaluru"""

prompt=template.format(text=text)

prompt

result=openai_model.invoke(prompt)

result

result.content

result=parser.parse(result.content)

result["name"]

result["age"]

result["city"]

chain= template | openai_model | parser

chain.invoke({"text":text})

topic="""AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods, thereby exemplifying a novel form of digital agency.[1]

Intelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria—such as a firm, a state, or a biome.[2]

Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion.[3] For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior.[4] Similarly, an evolutionary algorithm's behavior is guided by a fitness function.[5]

Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.

Intelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents—autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a "rational agent".[2]"""

template2=PromptTemplate(
    template='Give me 5 facts about {topic} \n {format_instruction}',
    input_variables=['topic'],
    partial_variables={'format_instruction': parser.get_format_instructions()}
)

chain= template2 | openai_model | parser

chain.invoke({"topic": topic})

"""## generate a strcuture output"""

from langchain.output_parsers import StructuredOutputParser, ResponseSchema

schema=[
    ResponseSchema(name="first_fact", description="first fact about text"),
    ResponseSchema(name="second_fact", description="second fact about text"),
    ResponseSchema(name="third_fact", description="third fact about text"),
]

parser=StructuredOutputParser.from_response_schemas(schema)

template3 = PromptTemplate(
    template='Give 3 fact about {topic} \n {format_instruction}',
    input_variables=['topic'],
    partial_variables={'format_instruction':parser.get_format_instructions()}
)

chain = template3 | openai_model | parser

result=chain.invoke({"topic":topic})

print(result)

print(result)

"""{'first_fact': 'Intelligent agents can range from simple to highly complex, including systems like a basic thermostat or control system, a human being, or larger systems like a firm, a state, or a biome.', 'second_fact': 'Intelligent agents operate based on an objective function which encapsulates their goals, and they are designed to create and execute plans that maximize the expected value of this function upon completion.', 'third_fact': 'Intelligent agents in artificial intelligence are closely related to agents in economics, cognitive science, ethics, philosophy of practical reason, socio-cognitive modeling, and computer social simulations.'}

## Pydantic Output parser
"""

from pydantic import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser

class Person(BaseModel):
    name:str=Field(description="name of person")
    age:int=Field(gt=18,description="age of person")
    city:str=Field(description="name of the city where the person is located")

parser=PydanticOutputParser(pydantic_object=Person)

parser.get_format_instructions()

template = PromptTemplate(
    template='Generate the nammme, age and city of a fictional {place} person \n {format_instruction}',
    input_variables=['place'],
    partial_variables={'format_instruction':parser.get_format_instructions()}
)

chain = template | openai_model | parser

result=chain.invoke({"place":"bengaluru"})

result

print(result.name)

print(result.age)

# Vectordatabase #textsplitter
1. pinecone(cloud vdb),weviate
#2. weviate, qurdant,milvus
3. mongodb
4. faiss, chroma(in memory)#poc
5. on disk(persist vectordb on disk)
6. aws opensearch

embdding, meta_data